from pathlib import Path

import numpy as np
import polars as pl

print("=== DIAGNÃ“STICO ESPECÃFICO DO BLOCKER AnyBURL/Ray ===\n")


def diagnosticar_entity_map(path: Path):
    print("1ï¸âƒ£  Verificando entity_map em", path)
    if not path.exists():
        print("   âš ï¸  entity_map.parquet nÃ£o encontrado, pulei esta etapa.\n")
        return
    df = pl.read_parquet(path)
    mask = pl.col("label").str.contains("1970-01-01") | pl.col("label").str.contains(
        "9999-12-31"
    )
    bad = df.filter(mask)
    if bad.height > 0:
        print(bad)
        ids = bad["id"].to_list()
        print(f"   ğŸ†” IDs problemÃ¡ticos: {ids}\n")
        # ALTERAÃ‡ÃƒO: para remover, descomente:
        # clean_df = df.filter(~mask)
        # clean_df.write_parquet(path.with_suffix('.clean.parquet'))
    else:
        print("   âœ… Nenhum timestamp invÃ¡lido encontrado.\n")


def diagnosticar_npy(split: str, base: Path):
    path = base / f"{split}.npy"
    print(f"2ï¸âƒ£  Verificando {split}.npy em {path}")
    if not path.exists():
        print("   âš ï¸  Arquivo nÃ£o encontrado, pulei esta etapa.\n")
        return
    arr = np.load(path)
    print(f"   âœ… Shape: {arr.shape}\n")


def diagnosticar_regras(path: Path):
    print("3ï¸âƒ£  Verificando rules_anyburl.tsv em", path)
    if not path.exists():
        print("   âš ï¸  Arquivo nÃ£o encontrado, pulei esta etapa.\n")
        return
    found = False
    with path.open("r", encoding="utf-8") as f:
        for idx, line in enumerate(f, 1):
            if "1970-01-01" in line or "9999-12-31" in line:
                if not found:
                    print("   âŒ Linhas com timestamps invÃ¡lidos:")
                    found = True
                print(f"     Linha {idx}: {line.strip()[:100]}...")
    if not found:
        print("   âœ… Nenhuma regra com timestamp invÃ¡lido.\n")


def check_anyburl_rules(path: Path):
    print("4ï¸âƒ£  Checando literal especÃ­fico em rules_anyburl.tsv", path)
    if not path.exists():
        print("   âš ï¸  Arquivo nÃ£o encontrado.\n")
        return
    content = path.read_text(encoding="utf-8")
    literal = "1970-01-01T22:59:59.151-03:00"
    if literal in content:
        print(f"   âŒ Literal '{literal}' encontrado nas regras!")
        for idx, line in enumerate(content.splitlines(), 1):
            if literal in line:
                print(f"     Linha {idx}: {line.strip()}")
    else:
        print("   âœ… Literal nÃ£o encontrado.\n")


def diagnosticar_entidades_orfas(base: Path):
    print("5ï¸âƒ£  VerificaÃ§Ã£o de Entidades Ã“rfÃ£s")
    mp = base / "entity_map.parquet"
    print("   ğŸ” Carregando mapeamento de entidades:", mp)
    if not mp.exists():
        print("   âš ï¸  entity_map.parquet nÃ£o encontrado.\n")
        return
    em = pl.read_parquet(mp)
    print(f"   ğŸ“Š Total de entidades: {em.height:,}")

    sets = {}
    for split in ["train", "valid", "test"]:
        npy = base / f"{split}.npy"
        print(f"   â€¢ {split}.npy:", npy)
        if not npy.exists():
            print("     âš ï¸  Arquivo nÃ£o encontrado")
            sets[split] = set()
            continue
        arr = np.load(npy)
        ents = set(np.unique(arr[:, [0, 2]].flatten()))
        sets[split] = ents
        print(f"     ğŸ¯ Entidades Ãºnicas: {len(ents):,}")
    orphans = {s: sets[s] - sets.get("train", set()) for s in ["valid", "test"]}
    print("\n   â“ Entidades Ã³rfÃ£s (nÃ£o no treino):")
    for s in orphans:
        print(f"     Em {s}: {len(orphans[s]):,}")
    if orphans.get("test"):
        print("   ğŸ“ Exemplos de Ã³rfÃ£s no teste:")
        for eid in list(orphans["test"])[:5]:
            lbl = em.filter(pl.col("id") == eid)["label"][0]
            print(f"     ID {eid}: {lbl}")


def find_problematic_entity():
    base = Path("outputs/pyclause")
    print("\nğŸ” Buscando a entidade problemÃ¡tica especÃ­fica...")
    mp = base / "entity_map.parquet"
    df = pl.read_parquet(mp)
    target = "2022-09-19T18:56:18.000-03:00"
    sel = df.filter(pl.col("label") == target)
    if sel.height == 0:
        print(f"   âŒ '{target}' nÃ£o encontrada no entity_map")
        return None
    eid = sel["id"][0]
    print(f"   âœ… Encontrada ID {eid} para label '{target}'")

    info = {}
    for split in ["train", "valid", "test"]:
        npy = base / f"{split}.npy"
        if npy.exists():
            data = np.load(npy)
            present = eid in set(data[:, [0, 2]].flatten())
            info[split] = present
            print(f"     {split}: {'âœ…' if present else 'âŒ'}")
    return eid, target, info


def analyze_orphan_pattern():
    """
    Analyzes the pattern of "orphan" entities in the test set that do not appear in the training set.

    This function loads entity mappings and train/test splits, identifies orphan entity IDs present in the test set but absent from the training set, and prints statistics and examples of these orphans. It also detects and reports patterns among the orphan labels, such as timestamps and unusually long IDs.

    Outputs:
        - Total number of orphan entities.
        - Example labels of orphan entities.
        - Detected patterns among orphan labels (timestamps and long IDs).
    """
    base = Path("outputs/pyclause")
    print("\nğŸ“Š Analisando padrÃ£o de Ã³rfÃ£s...")
    em = pl.read_parquet(base / "entity_map.parquet")
    train = np.load(base / "train.npy")[:, [0, 2]].flatten()
    test = np.load(base / "test.npy")[:, [0, 2]].flatten()
    train_set, test_set = set(train), set(test)
    orphans = test_set - train_set
    print(f"   ğŸ“ˆ Total de Ã³rfÃ£s: {len(orphans):,}")
    labels = [em.filter(pl.col("id") == eid)["label"][0] for eid in list(orphans)[:100]]
    print("\nğŸ·ï¸ Exemplos de labels Ã³rfÃ£s:")
    for i, label in enumerate(labels[:10], 1):
        print(f"     {i:2d}. {label}")
    ts = [label for label in labels if "T" in label and ":" in label]
    uid = [label for label in labels if len(label) > 20]
    print("\n   ğŸ§© PadrÃµes detectados:")
    print(f"     Timestamps: {len(ts)} ({len(ts) / len(labels) * 100:.1f}%)")
    print(f"     IDs longos: {len(uid)} ({len(uid) / len(labels) * 100:.1f}%)")


if __name__ == "__main__":
    base = Path("outputs/pyclause")
    # Gerais
    diagnosticar_entity_map(base / "entity_map.parquet")
    for sp in ["train", "valid", "test"]:
        diagnosticar_npy(sp, base)
    diagnosticar_regras(base / "rules_anyburl.tsv")
    check_anyburl_rules(base / "rules_anyburl.tsv")
    diagnosticar_entidades_orfas(base)
    # Blocker-specific
    result = find_problematic_entity()
    if result:
        eid, ts, info = result
        print(
            f"\nğŸ“‹ Resumo da entidade problemÃ¡tica: ID={eid}, ts={ts}, splits={info}\n"
        )
        if not info.get("train") and info.get("test"):
            print("âŒ CONFIRMADO: Entidade Ã³rfÃ£ causando o erro!\n")
    analyze_orphan_pattern()
